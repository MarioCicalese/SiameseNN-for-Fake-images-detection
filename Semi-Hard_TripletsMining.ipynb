{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import DatasetPath\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import timm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Dataset folder path\n",
    "DATA_DIR = DatasetPath.effectivePath\n",
    "\n",
    "# Device to run calculations on \n",
    "DEVICE = 'cuda'\n",
    "\n",
    "#CYCLE_GAN and PRO_GAN contains both real and fake images\n",
    "\n",
    "REAL_DIRS = [\"afhq\", \"celebahq\", \"coco\", \"ffhq\", \"imagenet\", \"landscape\", \"lsun\", \"metfaces\", \"cycle_gan\", \"pro_gan\"]\n",
    "\n",
    "FAKE_DIRS = [\"big_gan\", \"cips\", \"cycle_gan\", \"ddpm\", \"denoising_diffusion_gan\", \"diffusion_gan\", \"face_synthetics\", \n",
    "\t\t\t\t \"gansformer\", \"gau_gan\", \"generative_inpainting\", \"glide\", \"lama\", \"latent_diffusion\", \"mat\", \"palette\", \n",
    "\t\t\t\t \"pro_gan\", \"projected_gan\", \"sfhq\", \"stable_diffusion\", \"star_gan\", \"stylegan1\", \"stylegan2\", \"stylegan3\",\n",
    "\t\t\t\t \"taming_transformer\", \"vq_diffusion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read '.csv' file containing 'anchor', 'positive' and 'negative' triplets\n",
    "df = pd.read_csv(DATA_DIR + \"input.csv\")\n",
    "\n",
    "# Read '.csv' file containing BGR-Fourier path mappings \n",
    "mapping_df = pd.read_csv(DATA_DIR + \"path_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path_frequency_as_positive(df):\n",
    "\t\"\"\"\n",
    "\tPlot the frequency of paths in the 'positive' column of the DataFrame.\n",
    "\n",
    "\tThis function calculates the frequency of each unique path in the 'positive'\n",
    "\tcolumn of the provided DataFrame and plots the top 20 most frequent paths\n",
    "\tas a bar chart.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tdf (pandas.DataFrame): the DataFrame containing the 'positive' column with paths.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t# Calculate the frequency of 'positive' paths\n",
    "\tpositive_counts = df['positive'].value_counts()\n",
    "\n",
    "\t# Create the bar plot\n",
    "\tplt.figure(figsize=(25, 5))\n",
    "\tpositive_counts.head(20).plot(kind='bar')\n",
    "\tplt.title('Most Frequent Paths as \\'Positive\\'')\n",
    "\tplt.xlabel('Path')\n",
    "\tplt.ylabel('Frequency')\n",
    "\tplt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "\tplt.show()\n",
    "\n",
    "def plot_path_frequency_as_negative(df):\n",
    "\t\"\"\"\n",
    "\tPlot the frequency of paths in the 'negative' column of the DataFrame.\n",
    "\n",
    "\tThis function calculates the frequency of each unique path in the 'negative'\n",
    "\tcolumn of the provided DataFrame and plots the top 20 most frequent paths\n",
    "\tas a bar chart.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tdf (pandas.DataFrame): the DataFrame containing the 'negative' column with paths.\n",
    "\t\"\"\"\n",
    "\t# Calculate the frequency of 'negative' paths\n",
    "\tnegative_counts = df['negative'].value_counts()\n",
    "\n",
    "\t# Create the bar plot\n",
    "\tplt.figure(figsize=(25, 5))\n",
    "\tnegative_counts.head(20).plot(kind='bar')\n",
    "\tplt.title('Most Frequent Paths as \\'Negative\\'')\n",
    "\tplt.xlabel('Path')\n",
    "\tplt.ylabel('Frequency')\n",
    "\tplt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "\tplt.show()\n",
    "\n",
    "def plot_real_fake_count(df):\n",
    "\t\"\"\"\n",
    "\tPlot the count of 'real' and 'fake' paths in the DataFrame.\n",
    "\n",
    "\tThis function calculates the total number of paths containing the substring\n",
    "\t'real' and 'fake' in the 'anchor', 'positive', and 'negative' columns of the\n",
    "\tprovided DataFrame. It then plots these counts as a horizontal bar chart.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tdf (pandas.DataFrame): the DataFrame containing 'anchor', 'positive', and 'negative' columns with paths.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t# Count occurrences of 'real' and 'fake' in the 'anchor' column\n",
    "\treal_count = df['anchor'].str.contains('real').sum()\n",
    "\tfake_count = df['anchor'].str.contains('fake').sum()\n",
    "\n",
    "\t# Prepare data for plotting\n",
    "\tcounts = {'real': real_count, 'fake': fake_count}\n",
    "\tcounts_df = pd.DataFrame(list(counts.items()), columns=['Type', 'Count'])\n",
    "\n",
    "\t# Plot horizontal bar chart\n",
    "\tax = counts_df.plot(kind='barh', x='Type', y='Count', legend=False, color=['blue', 'red'])\n",
    "\tplt.title('Number of images in the Training Set per category')\n",
    "\tplt.xlabel('Count')\n",
    "\tplt.ylabel('Type')\n",
    "\n",
    "\t# Add text annotations to the bars\n",
    "\tfor index, value in enumerate(counts_df['Count']):\n",
    "\t\tax.text(value, index, str(value), va='center')\n",
    "\n",
    "\t# Expand x-axis to accommodate annotations\n",
    "\tplt.xlim(right=max(counts_df['Count']) * 1.2)\n",
    "\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path_frequency_as_positive(df)\n",
    "plot_path_frequency_as_negative(df)\n",
    "plot_real_fake_count(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APN_Model(nn.Module):\n",
    "\t\"\"\"\n",
    "\tDefines a neural network model class APN_Model that uses an EfficientNet (specifically the B0 version) as its backbone.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, emb_size = 512):\n",
    "\t\t\"\"\"\n",
    "\t\tInitializes the APN_Model with a specific model and a classifier that outputs embedding vector of the specified size.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\temb_size (int, optional): the size of the output embedding vector (default is 512).\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(APN_Model, self).__init__()\n",
    "\n",
    "\t\t# Define the model to use \n",
    "\t\tself.efficientnet = timm.create_model('tf_efficientnetv2_b0', pretrained = True)\n",
    "\t\t\n",
    "\t\t# Replace the classifier layer with a linear layer that outputs embeddings of size `emb_size`\n",
    "\t\tself.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features = emb_size)\n",
    "\n",
    "\tdef forward(self, images):\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms the forward pass of the model, which takes a batch of images and returns their embeddings.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\t\timages (torch.Tensor): a batch of images to process.\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\t\tembeddings (torch.Tensor): a batch of embeddings of size `emb_size`.\n",
    "\t\t\"\"\"\n",
    "\t\tembeddings = self.efficientnet(images)\n",
    "\t\treturn embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN mod to accept greyscale fourier spectrum images instead of RGB\n",
    "\n",
    "model = APN_Model()\n",
    "# model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageEmbeddings(img_path, model):\n",
    "\t\"\"\"\n",
    "\tGenerates embeddings for a given image using the provided model.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\t\timg_path (str): the path to the input image.\n",
    "\t\tmodel (torch.nn.Module): the PyTorch model used to generate the image embeddings.\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\t\timg_enc (numpy.ndarray): the embeddings of the input image.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t# Read the image from the specified directory\n",
    "\timg = io.imread(DATA_DIR + img_path)\n",
    "\tprint(img.shape)\n",
    "\t# Add a new dimension to the image array to match the expected input shape of the model\n",
    "\timg = np.expand_dims(img, 0)\n",
    "\tprint(img.shape)\n",
    "\t# Convert the NumPy array to a PyTorch tensor and normalize pixel values to the range [0, 1]\n",
    "\timg = torch.from_numpy(img) / 255.0\n",
    "\tprint(img.shape)\n",
    "\t# Set the model to evaluation mode\n",
    "\tmodel.eval()\n",
    "\t\n",
    "\t# Disable gradient calculation for efficiency\n",
    "\twith torch.no_grad():\n",
    "\t\t# Move the image tensor to the appropriate device (CPU or GPU)\n",
    "\t\timg = img.to(DEVICE)\n",
    "\t\t\n",
    "\t\t# Add a batch dimension, pass the image through the model to get the embeddings\n",
    "\t\timg_enc = model(img.unsqueeze(0))\n",
    "\t\tprint(img.shape)\n",
    "\t\t# Detach the embeddings from the computation graph and move them back to the CPU\n",
    "\t\timg_enc = img_enc.detach().cpu().numpy()\n",
    "\t\t\n",
    "\t\t# Convert the embeddings to a NumPy array\n",
    "\t\timg_enc = np.array(img_enc)\n",
    "\n",
    "\treturn img_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_to_BGR_mapping(df, mapping_df):\n",
    "    \"\"\"\n",
    "    Replaces frequency domain image paths with corresponding BGR image paths.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df (Pandas.Dataframe): the DataFrame containing the CSV file with the triplets having frequency domain paths.\n",
    "    mapping_df (Pandas.Dataframe): the DataFrame containing the CSV file with the BGR-Fourier mappings\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a mapping dictionary from frequency paths to RGB paths\n",
    "    path_mapping_dict = pd.Series(mapping_df['RGB Path'].values, index=mapping_df['Fourier Path']).to_dict()\n",
    "\n",
    "    # Replace frequency paths with RGB paths directly\n",
    "    df['anchor'] = df['anchor'].map(path_mapping_dict).fillna(df['anchor'])\n",
    "    df['positive'] = df['positive'].map(path_mapping_dict).fillna(df['positive'])\n",
    "    df['negative'] = df['negative'].map(path_mapping_dict).fillna(df['negative'])\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fourier_to_BGR_mapping(df, mapping_df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = {}  # Initialize an empty dictionary to store image embeddings\n",
    "\n",
    "# Loop through each image path in the 'anchor' column of the DataFrame\n",
    "for img_path in tqdm(df['anchor'], total=len(df), desc=\"Generating embeddings\"):\n",
    "\t# Generate and store the embedding for each anchor image in the dictionary\n",
    "\tembedding_dict[img_path] = getImageEmbeddings(img_path, model)\n",
    "\n",
    "# Map the embeddings to the 'anchor_emb' column using the paths from the 'anchor' column\n",
    "df['anchor_emb'] = df['anchor'].map(embedding_dict)\n",
    "\n",
    "# Map the embeddings to the 'positive_emb' column using the paths from the 'positive' column\n",
    "df['positive_emb'] = df['positive'].map(embedding_dict)\n",
    "\n",
    "# Map the embeddings to the 'negative_emb' column using the paths from the 'negative' column\n",
    "df['negative_emb'] = df['negative'].map(embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "\t\"\"\"\n",
    "\tCalculate the Euclidean distance between two vectors.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\ta (numpy.ndarray): the first vector.\n",
    "\tb (numpy.ndarray): the second vector.\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\t(float): the Euclidean distance between vectors `a` and `b`.\n",
    "\t\"\"\"\n",
    "\treturn np.linalg.norm(a - b)  # Calculate and return the Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distances between anchor and positive embeddings\n",
    "df['dist_anchor_positive'] = [euclidean_distance(row['anchor_emb'], row['positive_emb']) for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Calculating distances (anchor-positive)\")]\n",
    "\n",
    "# Calculate the distances between anchor and negative embeddings\n",
    "df['dist_anchor_negative'] = [euclidean_distance(row['anchor_emb'], row['negative_emb']) for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Calculating distances (anchor-negative)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2  # Set the margin for semi-hard triplets\n",
    "\n",
    "# Filter the DataFrame to select semi-hard triplets based on the defined condition\n",
    "semi_hard_triplets = df[\n",
    "\t(df['dist_anchor_positive'] < df['dist_anchor_negative']) &  # Check if the distance between anchor and positive embeddings is less than the distance between anchor and negative embeddings\n",
    "\t(df['dist_anchor_negative'] < (df['dist_anchor_positive'] + margin))  # Check if the distance between anchor and negative embeddings is less than the distance between anchor and positive embeddings plus the margin\n",
    "]\n",
    "\n",
    "# Print the semi-hard triplets\n",
    "print(semi_hard_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BGR_to_Fourier_mapping(df, mapping_df):\n",
    "    \"\"\"\n",
    "    Replaces BGR image paths with corresponding frequency domain image paths.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df (Pandas.Dataframe): the DataFrame containing the CSV file with the triplets having BGR paths.\n",
    "    mapping_df (Pandas.Dataframe): the DataFrame containing the CSV file with the BGR-Fourier mappings\n",
    "\n",
    "    \"\"\"\n",
    "    # Create a mapping dictionary from RGB paths to frequency paths\n",
    "    path_mapping_dict = pd.Series(mapping_df['Fourier Path'].values, index=mapping_df['RGB Path']).to_dict()\n",
    "\n",
    "    # Replace frequency paths with RGB paths directly\n",
    "    df['anchor'] = df['anchor'].map(path_mapping_dict).fillna(df['anchor'])\n",
    "    df['positive'] = df['positive'].map(path_mapping_dict).fillna(df['positive'])\n",
    "    df['negative'] = df['negative'].map(path_mapping_dict).fillna(df['negative'])\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_hard_triplets = BGR_to_Fourier_mapping(semi_hard_triplets, mapping_df)\n",
    "print(semi_hard_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(df, filename, path):\n",
    "\t\"\"\"\n",
    "\tSplits the DataFrame in chunks to enable tqdm progress visualization while converting the DataFrame into a '.csv' file.\n",
    "\n",
    "\tParametres\n",
    "\t----------\n",
    "\t\tdf (pd.DataFrame): the DataFrame to convert.\n",
    "\t\tfilename (str): the desired file name (comprehensive of '.csv' extension).\n",
    "\t\tpath (str): the path where the '.csv' will be stored.\n",
    "\t\"\"\"\n",
    "\tchunks = np.array_split(df.index, 100)\n",
    "\tfor chunck, subset in enumerate(tqdm(chunks, desc=\"Creating \\'\" + filename + \"\\' file\")):\n",
    "\t\tif chunck == 0: # first row\n",
    "\t\t\tdf.loc[subset].to_csv(path, mode='w', index=False)\n",
    "\t\telse:\n",
    "\t\t\tdf.loc[subset].to_csv(path, header=None, mode='a', index=False)\n",
    "\n",
    "\tprint(\"\\'\" + filename + \"\\' has been successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame containing only the 'anchor', 'positive', and 'negative' columns from semi_hard_triplets\n",
    "filtered_input_df = semi_hard_triplets[['anchor', 'positive', 'negative']].copy()\n",
    "\n",
    "# Print the selected triplets DataFrame\n",
    "print(filtered_input_df)\n",
    "\n",
    "# Save to '.csv'\n",
    "df_to_csv(filtered_input_df, \"filtered_input.csv\", DATA_DIR + \"filtered_input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the '.csv' file and load it into a DataFrame\n",
    "df = pd.read_csv(DATA_DIR + \"filtered_input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path_frequency_as_positive(df)\n",
    "plot_path_frequency_as_negative(df)\n",
    "plot_real_fake_count(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read lengths of CSV files\n",
    "input_length = len(pd.read_csv(DATA_DIR + 'input.csv'))\n",
    "filtered_input_length = len(df)\n",
    "\n",
    "# Prepare data for plotting\n",
    "lengths = {'Mined': filtered_input_length, 'Unmined': input_length}\n",
    "lengths_df = pd.DataFrame(list(lengths.items()), columns=['File', 'Length'])\n",
    "\n",
    "# Plot horizontal bar chart\n",
    "ax = lengths_df.plot(kind='barh', x='File', y='Length', legend=False, color=['blue', 'red'])\n",
    "plt.title('Variation in triplets number after Semi-Hard Triplets Mining')\n",
    "plt.xlabel('N. of Triplets')\n",
    "plt.ylabel('File')\n",
    "\n",
    "# Add text annotations to the bars\n",
    "for index, value in enumerate(lengths_df['Length']):\n",
    "\tax.text(value, index, str(value), va='center')\n",
    "\n",
    "# Expand x-axis to accommodate annotations\n",
    "plt.xlim(right=max(lengths_df['Length']) * 1.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code adresses the issue with path differences beetween Google and Windows when colab is used \n",
    "# (This doesn't change anything if colab wasn't used)\n",
    "\n",
    "# Replace '\\' with '/' in the whole file\n",
    "df = df.applymap(lambda x: x.replace('/', '\\\\') if isinstance(x, str) else x)\n",
    "\n",
    "# Overwrite the '.csv' file with the updated DataFrame\n",
    "if os.path.exists(DATA_DIR + \"filtered_input.csv\"):\n",
    "\t\tos.remove(DATA_DIR + \"filtered_input.csv\")\n",
    "df.to_csv(DATA_DIR + \"filtered_input.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dirs(filtered_input_df):\n",
    "\t\"\"\"\n",
    "\tRetrieves image source directories from the dataset.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\t\tfiltered_input_df (pandas.DataFrame): the dataframe containing the semi-hard mined triplets.\n",
    "\tReturns\n",
    "\t-------\n",
    "\t\treal_dirs (set of str): a set of unique directories that contain real images.\n",
    "\t\tfake_dirs (set of str): a set of unique directories that contain fake images.\n",
    "\t\"\"\"\n",
    "\t# Initialize lists to store directories for real and fake images\n",
    "\treal_dirs_list = []\n",
    "\tfake_dirs_list = []\n",
    "\n",
    "\t# Iterate through each row in the dataframe with a progress bar\n",
    "\tfor index, row in tqdm(filtered_input_df.iterrows(), total=filtered_input_df.shape[0]):\n",
    "\t\t# Extract the top-level directory from the image path\n",
    "\t\tdir = row[\"anchor\"].split('fourier\\\\fourier\\\\')[1].split('+')[0]\n",
    "\n",
    "\t\t# Categorize the directory as 'real' or 'fake' based on its presence in REAL_DIRS\n",
    "\t\tif dir in REAL_DIRS:\n",
    "\t\t\treal_dirs_list.append(dir)\n",
    "\t\telse:\n",
    "\t\t\tfake_dirs_list.append(dir)\n",
    "\n",
    "\treal_dirs = sorted(set(real_dirs_list))\n",
    "\tfake_dirs = sorted(set(fake_dirs_list))\n",
    "\n",
    "\t# Return the lists of real and fake directories\n",
    "\treturn real_dirs, fake_dirs\n",
    "\n",
    "\n",
    "def train_test_split_rebalance(filtered_input_df, test_df):\n",
    "\t\"\"\"\n",
    "\tRebalances the test dataset to achieve an 80/20 train-test split ratio.\n",
    "\n",
    "\tThis function rebalances the test dataset by dropping a calculated number of \n",
    "\tsamples from each directory of real and fake images to achieve an 80/20 \n",
    "\ttrain-test split ratio. The function also saves the old test set before \n",
    "\trebalancing.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tfiltered_input_df (pandas.DataFrame): the DataFrame containing the filtered input data.\n",
    "\ttest_df (pandas.DataFrame): the DataFrame containing the initial test data.\n",
    "\n",
    "\tNotes\n",
    "\t-----\n",
    "\t- This function assumes the presence of 'real' and 'fake' columns in the \n",
    "\t  `test_df` DataFrame, which contain paths to the real and fake images, \n",
    "\t  respectively.\n",
    "\t- The function will save the old test set to a CSV file named \n",
    "\t  \"unbalanced_testSet.csv\" and the rebalanced test set to a CSV file named \n",
    "\t  \"testSet.csv\" in the directory specified by `DATA_DIR`.\n",
    "\t- The function uses the helper function `get_input_dirs` to obtain directories \n",
    "\t  containing real and fake images and `df_to_csv` to save DataFrames to CSV files.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t# Initialization\n",
    "\tbalanced_test_df = pd.DataFrame(columns=['real', 'fake'])\n",
    "\tinput_size = len(filtered_input_df)\n",
    "\treal_dirs, fake_dirs = get_input_dirs(filtered_input_df)\n",
    "\tprint(real_dirs)\n",
    "\tprint(fake_dirs)\n",
    "\n",
    "\trebalanced_size = round(input_size * 20 / 80)\n",
    "\tprint(f\"Current Test set size:{len(test_df) * 2}(Train-Test split ratio: {(input_size * 100 / (input_size + (len(test_df)* 2))):.2f}/{(len(test_df) * 2 * 100 / (input_size + (len(test_df)* 2))):.2f})\")\n",
    "\tprint(f\"Balanced Test set size:{rebalanced_size}(Train-Test split ratio: 80/20)\")\n",
    "\n",
    "\t# Number of tuples to sample from each real images directory\n",
    "\treal_sample_size = round(rebalanced_size / 2 / len(real_dirs))\n",
    "\ti = 1\n",
    "\t#Iterate through the dataset partition and sample the same number of tuples for each fake images directory\n",
    "\tfor dir in tqdm(real_dirs, desc=\"Test set Real images sampling\"):\n",
    "\t\tsampled_size = 0\n",
    "\t\tfor index, row in test_df.iterrows():\n",
    "\t\t\tif sampled_size < real_sample_size:\n",
    "\t\t\t\timage_path = row[\"real\"]\n",
    "\t\t\t\tsplitted_path = image_path.split('fourier\\\\fourier\\\\')[1].split('+')[0]\n",
    "\t\t\t\tif dir==splitted_path:\n",
    "\t\t\t\t\tbalanced_test_df.loc[i] = [image_path, None]\n",
    "\t\t\t\t\tsampled_size+=1\n",
    "\t\t\t\t\ti+=1\n",
    "\t\t\telse: break\n",
    "\t\n",
    "\t# Number of tuples to sample from each fake images directory\n",
    "\tfake_sample_size = round(rebalanced_size / 2 / len(fake_dirs))\n",
    "\ti = 1\n",
    "\t#Iterate through the dataset partition and sample the same number of tuples for each fake images directory\n",
    "\tfor dir in tqdm(fake_dirs, desc=\"Test set Fake images sampling\"):\n",
    "\t\t\tsampled_size = 0\n",
    "\t\t\tfor index, row in test_df.iterrows():\n",
    "\t\t\t\t\tif sampled_size < fake_sample_size:\n",
    "\t\t\t\t\t\t\timage_path = row[\"fake\"]\n",
    "\t\t\t\t\t\t\tsplitted_path = image_path.split('fourier\\\\fourier\\\\')[1].split('+')[0]\n",
    "\t\t\t\t\t\t\tif dir == splitted_path:\n",
    "\t\t\t\t\t\t\t\t\tbalanced_test_df.loc[i] = [balanced_test_df.loc[i][\"real\"], image_path]\n",
    "\t\t\t\t\t\t\t\t\tsampled_size+=1\n",
    "\t\t\t\t\t\t\t\t\ti+=1\n",
    "\n",
    "\t\t\t\t\telse: break\n",
    "\t\n",
    "\tprint(f\"Test Set size after operations:{len(balanced_test_df) * 2}\")\n",
    "\n",
    "\t# Store the old version of the Test Set and Overwrite the Test Set with the rebalanced one\n",
    "\tdf_to_csv(test_df, \"unbalanced_testSet.csv\", DATA_DIR + \"unbalanced_testSet.csv\")\n",
    "\tif os.path.exists(DATA_DIR + \"testSet.csv\"):\n",
    "\t\tos.remove(DATA_DIR + \"testSet.csv\")\n",
    "\tdf_to_csv(balanced_test_df, \"testSet.csv\", DATA_DIR + \"testSet.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_input_df = pd.read_csv(DATA_DIR + \"filtered_input.csv\")\n",
    "test_df = pd.read_csv(DATA_DIR + \"testSet.csv\")\n",
    "\n",
    "train_test_split_rebalance(filtered_input_df, test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DETECTIVE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
