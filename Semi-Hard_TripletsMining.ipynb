{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import DatasetPath\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import timm\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Dataset folder path\n",
    "DATA_DIR = DatasetPath.effectivePath\n",
    "\n",
    "# Device to run calculations on \n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read '.csv' file containing 'anchor', 'positive' and 'negative' triplets\n",
    "df = pd.read_csv(DATA_DIR + \"input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APN_Model(nn.Module):\n",
    "\t\"\"\"\n",
    "\tDefines a neural network model class APN_Model that uses an EfficientNet (specifically the B0 version) as its backbone.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, emb_size = 512):\n",
    "\t\t\"\"\"\n",
    "\t\tInitializes the APN_Model with a specific model and a classifier that outputs embedding vector of the specified size.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\temb_size (int, optional): the size of the output embedding vector (default is 512).\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(APN_Model, self).__init__()\n",
    "\n",
    "\t\t# Define the model to use \n",
    "\t\tself.efficientnet = timm.create_model('tf_efficientnetv2_b0', pretrained = True)\n",
    "\t\t\n",
    "\t\t# Replace the classifier layer with a linear layer that outputs embeddings of size `emb_size`\n",
    "\t\tself.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features = emb_size)\n",
    "\n",
    "\tdef forward(self, images):\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms the forward pass of the model, which takes a batch of images and returns their embeddings.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\t\timages (torch.Tensor): a batch of images to process.\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\t\tembeddings (torch.Tensor): a batch of embeddings of size `emb_size`.\n",
    "\t\t\"\"\"\n",
    "\t\tembeddings = self.efficientnet(images)\n",
    "\t\treturn embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN mod to accept greyscale fourier spectrum images instead of RGB\n",
    "\n",
    "model = APN_Model()\n",
    "model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageEmbeddings(img_path, model):\n",
    "\t\"\"\"\n",
    "\tGenerates embeddings for a given image using the provided model.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\t\timg_path (str): the path to the input image.\n",
    "\t\tmodel (torch.nn.Module): the PyTorch model used to generate the image embeddings.\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\t\timg_enc (numpy.ndarray): the embeddings of the input image.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t# Read the image from the specified directory\n",
    "\timg = io.imread(DATA_DIR + img_path)\n",
    "\n",
    "\t# Add a new dimension to the image array to match the expected input shape of the model\n",
    "\timg = np.expand_dims(img, 0)\n",
    "\t\n",
    "\t# Convert the NumPy array to a PyTorch tensor and normalize pixel values to the range [0, 1]\n",
    "\timg = torch.from_numpy(img) / 255.0\n",
    "\t\n",
    "\t# Set the model to evaluation mode\n",
    "\tmodel.eval()\n",
    "\t\n",
    "\t# Disable gradient calculation for efficiency\n",
    "\twith torch.no_grad():\n",
    "\t\t# Move the image tensor to the appropriate device (CPU or GPU)\n",
    "\t\timg = img.to(DEVICE)\n",
    "\t\t\n",
    "\t\t# Add a batch dimension, pass the image through the model to get the embeddings\n",
    "\t\timg_enc = model(img.unsqueeze(0))\n",
    "\t\t\n",
    "\t\t# Detach the embeddings from the computation graph and move them back to the CPU\n",
    "\t\timg_enc = img_enc.detach().cpu().numpy()\n",
    "\t\t\n",
    "\t\t# Convert the embeddings to a NumPy array\n",
    "\t\timg_enc = np.array(img_enc)\n",
    "\n",
    "\treturn img_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = {}  # Initialize an empty dictionary to store image embeddings\n",
    "\n",
    "# Loop through each image path in the 'anchor' column of the DataFrame\n",
    "for img_path in tqdm(df['anchor'], total=len(df), desc=\"Generating embeddings\"):\n",
    "    # Generate and store the embedding for each anchor image in the dictionary\n",
    "    embedding_dict[img_path] = getImageEmbeddings(img_path, model)\n",
    "\n",
    "# Map the embeddings to the 'anchor_emb' column using the paths from the 'anchor' column\n",
    "df['anchor_emb'] = df['anchor'].map(embedding_dict)\n",
    "\n",
    "# Map the embeddings to the 'positive_emb' column using the paths from the 'positive' column\n",
    "df['positive_emb'] = df['positive'].map(embedding_dict)\n",
    "\n",
    "# Map the embeddings to the 'negative_emb' column using the paths from the 'negative' column\n",
    "df['negative_emb'] = df['negative'].map(embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a (numpy.ndarray): the first vector.\n",
    "    b (numpy.ndarray): the second vector.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (float): the Euclidean distance between vectors `a` and `b`.\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(a - b)  # Calculate and return the Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distances between anchor and positive embeddings\n",
    "df['dist_anchor_positive'] = [euclidean_distance(row['anchor_emb'], row['positive_emb']) for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Calculating distances (anchor-positive)\")]\n",
    "\n",
    "# Calculate the distances between anchor and negative embeddings\n",
    "df['dist_anchor_negative'] = [euclidean_distance(row['anchor_emb'], row['negative_emb']) for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Calculating distances (anchor-negative)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2  # Set the margin for semi-hard triplets\n",
    "\n",
    "# Filter the DataFrame to select semi-hard triplets based on the defined condition\n",
    "semi_hard_triplets = df[\n",
    "    (df['dist_anchor_positive'] < df['dist_anchor_negative']) &  # Check if the distance between anchor and positive embeddings is less than the distance between anchor and negative embeddings\n",
    "    (df['dist_anchor_negative'] < (df['dist_anchor_positive'] + margin))  # Check if the distance between anchor and negative embeddings is less than the distance between anchor and positive embeddings plus the margin\n",
    "]\n",
    "\n",
    "# Print the semi-hard triplets\n",
    "print(semi_hard_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(df, filename, path):\n",
    "\t\"\"\"\n",
    "\tSplits the DataFrame in chunks to enable tqdm progress visualization while converting the DataFrame into a '.csv' file.\n",
    "\n",
    "\tParametres\n",
    "\t----------\n",
    "\t\tdf (pd.DataFrame): the DataFrame to convert.\n",
    "\t\tfilename (str): the desired file name (comprehensive of '.csv' extension).\n",
    "\t\tpath (str): the path where the '.csv' will be stored.\n",
    "\t\"\"\"\n",
    "\tchunks = np.array_split(df.index, 100)\n",
    "\tfor chunck, subset in enumerate(tqdm(chunks, desc=\"Creating \\'\" + filename + \"\\' file\")):\n",
    "\t\tif chunck == 0: # first row\n",
    "\t\t\tdf.loc[subset].to_csv(path, mode='w', index=False)\n",
    "\t\telse:\n",
    "\t\t\tdf.loc[subset].to_csv(path, header=None, mode='a', index=False)\n",
    "\n",
    "\tprint(\"\\'\" + filename + \"\\' has been successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame containing only the 'anchor', 'positive', and 'negative' columns from semi_hard_triplets\n",
    "filtered_input_df = semi_hard_triplets[['anchor', 'positive', 'negative']].copy()\n",
    "\n",
    "# Print the selected triplets DataFrame\n",
    "print(filtered_input_df)\n",
    "\n",
    "# Save to '.csv'\n",
    "df_to_csv(filtered_input_df, \"filtered_input.csv\", DATA_DIR + \"filtered_input.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DETECTIVE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
