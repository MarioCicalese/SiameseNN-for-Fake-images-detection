{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import DatasetPath\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import timm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Dataset folder path\n",
    "DATA_DIR = DatasetPath.effectivePath\n",
    "\n",
    "# HYPERPARAMETRES\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "LR = 0.001\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "# Device to run calculations on \n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_DIR + \"input.csv\")\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size = 0.20, random_state = 42)\n",
    "print(len(train_df))\n",
    "print(len(valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to provide useful functions and prepare the data for NN use \n",
    "class APN_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Uploads images from Dataset and set them up for Neural Network use.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        Dataset (pd.DataFrame): the DataFrame containing the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Initializes the class with the DataFrame in input.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            df (pd.DataFrame): the DataFrame containing the dataset.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Calculates the number of tuples in the dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            (int): number of tuples in the dataset.\n",
    "        \"\"\"    \n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the images at the given row index.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            idx (int): dataset row index.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            A_img, P_img, N_img (ndarray): the anchor, positive and negative images at row[idx] \n",
    "        \"\"\"\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        A_img = io.imread(DATA_DIR + row.anchor)\n",
    "        P_img = io.imread(DATA_DIR + row.positive)\n",
    "        N_img = io.imread(DATA_DIR + row.negative)\n",
    "\n",
    "        #Permute because the third channel has to be in first channel in torch\n",
    "\n",
    "        #A_img = torch.from_numpy(A_img).permute(2, 0, 1) / 255.0\n",
    "        #P_img = torch.from_numpy(P_img).permute(2, 0, 1) / 255.0\n",
    "        #N_img = torch.from_numpy(N_img).permute(2, 0, 1) / 255.0\n",
    "\n",
    "\n",
    "        A_img = np.expand_dims(A_img, 0)\n",
    "        P_img = np.expand_dims(P_img, 0)\n",
    "        N_img = np.expand_dims(N_img, 0)\n",
    "\n",
    "        A_img = torch.from_numpy(A_img) / 255.0\n",
    "        P_img = torch.from_numpy(P_img) / 255.0\n",
    "        N_img = torch.from_numpy(N_img) / 255.0\n",
    "\n",
    "        #A_img = torch.from_numpy(A_img.astype(np.int32)) / 65536.0\n",
    "        #P_img = torch.from_numpy(P_img.astype(np.int32)) / 65536.0\n",
    "        #N_img = torch.from_numpy(N_img.astype(np.int32)) / 65536.0\n",
    "\n",
    "        return A_img, P_img, N_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of trainset: 16000\n",
      "Size of validset: 4000\n"
     ]
    }
   ],
   "source": [
    "# APN_Dataset objects creation\n",
    "\n",
    "trainset = APN_Dataset(train_df)\n",
    "validset = APN_Dataset(valid_df)\n",
    "\n",
    "print(f\"Size of trainset: {len(trainset)}\")\n",
    "print(f\"Size of validset: {len(validset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of batches in trainloader : 250\n",
      "No. of batches in validloader : 63\n"
     ]
    }
   ],
   "source": [
    "# DataLoader creation to handle loading data into memory\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "validloader = DataLoader(validset, batch_size = BATCH_SIZE)\n",
    "\n",
    "print(f\"No. of batches in trainloader : {len(trainloader)}\")\n",
    "print(f\"No. of batches in validloader : {len(validloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APN_Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a neural network model class APN_Model that uses an EfficientNet (specifically the B0 version) as its backbone.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, emb_size = 512):\n",
    "        \"\"\"\n",
    "        Initializes the APN_Model with a specific model and a classifier that outputs embedding vector of the specified size.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        emb_size (int, optional): the size of the output embedding vector (default is 512).\n",
    "        \"\"\"\n",
    "        super(APN_Model, self).__init__()\n",
    "\n",
    "        # Define the model to use \n",
    "        self.efficientnet = timm.create_model('tf_efficientnetv2_b0', pretrained = False)\n",
    "        \n",
    "        # Replace the classifier layer with a linear layer that outputs embeddings of size `emb_size`\n",
    "        self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features = emb_size)\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the model, which takes a batch of images and returns their embeddings.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            images (torch.Tensor): a batch of images to process.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            embeddings (torch.Tensor): a batch of embeddings of size `emb_size`.\n",
    "        \"\"\"\n",
    "        embeddings = self.efficientnet(images)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN mod to accept greyscale fourier spectrum images instead of RGB\n",
    "\n",
    "model = APN_Model()\n",
    "model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False);\n",
    "\n",
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, dataloader, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch using the provided dataloader, optimizer, and criterion.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        model (torch.nn.Module): the neural network model to be trained.\n",
    "        dataloader (torch.utils.data.DataLoader): the dataloader providing batches of anchor, positive, and negative image triplets.\n",
    "        optimizer (torch.optim.Optimizer): the optimizer used to update the model's parameters.\n",
    "        criterion (function): the loss function used to compute the loss between the model's outputs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        (float) : the average training loss over all batches.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sets the model to training mode\n",
    "    model.train() #ON Dropout\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Iterates over the batches of data provided by the dataloader.\n",
    "    # Each batch consists of triplets: anchor (A), positive (P), and negative (N) images.\n",
    "    for A, P, N in tqdm(dataloader):\n",
    "        # Moves the anchor, positive, and negative images to the specified device.\n",
    "        A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
    "\n",
    "        # Passes the anchor, positive, and negative images through the model to obtain their embeddings.\n",
    "        A_embs = model(A)\n",
    "        P_embs = model(P)\n",
    "        N_embs = model(N)\n",
    "\n",
    "        # Computes the loss using the specified loss function\n",
    "        loss = criterion(A_embs, P_embs, N_embs)\n",
    "\n",
    "        # Clears the gradients of all optimized parameters.\n",
    "        # Important to prevent accumulation of gradients from multiple forward passes.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Computes the gradient of the loss with respect to the model's parameters (backpropagation).\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updates the model's parameters based on the computed gradients.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Updates toal loss at the end of each iteration\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model, dataloader, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the model using the provided dataloader and criterion.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        model (torch.nn.Module): the neural network model to be evaluated.\n",
    "        dataloader (torch.utils.data.DataLoader): the dataloader providing batches of anchor, positive, and negative image triplets.\n",
    "        criterion (function): the loss function used to compute the loss between the model's outputs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        (float): the average validation loss over all batches.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sets the model to evaluation mode\n",
    "    model.eval() #OFF Dropout\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Disables gradient calculation.\n",
    "    # Important to reduce memory usage and speed up computations since gradients are not needed.\n",
    "    with torch.no_grad():\n",
    "        # Iterates over the batches of data provided by the dataloader.\n",
    "        for A, P, N in tqdm(dataloader):\n",
    "             # Moves the anchor, positive, and negative images to the specified device.\n",
    "            A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
    "\n",
    "            # Passes the anchor, positive, and negative images through the model to obtain their embeddings.\n",
    "            A_embs = model(A)\n",
    "            P_embs = model(P)\n",
    "            N_embs = model(N)\n",
    "\n",
    "            # Computes the loss using the specified loss function\n",
    "            loss = criterion(A_embs, P_embs, N_embs)\n",
    "\n",
    "            # Updates toal loss at the end of each iteration\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the loss function and the optimizer to utilize.\n",
    "\n",
    "criterion = nn.TripletMarginLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = DATA_DIR + 'best_model.pt'\n",
    "loss_path =  DATA_DIR + 'best_valid_loss.txt'\n",
    "\n",
    "def save_checkpoint(best_valid_loss):\n",
    "    \"\"\"\n",
    "    Saves best model along with its valid loss to a '.txt' file\n",
    "\n",
    "    Parametres\n",
    "    ----------\n",
    "        best_valid_loss (float): the best valid loss calculated among all training sessions.\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    with open(loss_path, 'w') as f:\n",
    "        f.write(str(best_valid_loss))\n",
    "\n",
    "    print(\"CHECKPOINT_SAVED\")\n",
    "\n",
    "def load_checkpoint():\n",
    "    \"\"\"\n",
    "    Loads the best model and its valid loss from a '.txt' file. In case one of these can't be found, the training starts from scratch\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        best_valid_loss (float, np.Inf): if the best valid loss exists, returns a float; else returns an Infinite value\n",
    "    \"\"\"\n",
    "    if os.path.exists(model_path) and os.path.exists(loss_path):\n",
    "        print(\"CHECKPOINT_LOADED\")\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        with open(loss_path, 'r') as f:\n",
    "            best_valid_loss = float(f.read())\n",
    "            return best_valid_loss\n",
    "\n",
    "    print(\"UNABLE_TO_LOAD_CHECKPOINT\")\n",
    "    return np.Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the best validation loss from a previously saved checkpoint.\n",
    "# (This allows the training process to resume from the best state observed so far)\n",
    "best_valid_loss = load_checkpoint()\n",
    "\n",
    "# Loops over the specified number of epochs.\n",
    "for i in range(EPOCHS):\n",
    "\n",
    "    # Trains and evaluates the model\n",
    "    train_loss = train_fn(model, trainloader, optimizer, criterion)\n",
    "    valid_loss = eval_fn(model, validloader, criterion)\n",
    "\n",
    "    # If the validation loss has improved, it saves the current state of the model and updates the best valid loss\n",
    "    if valid_loss < best_valid_loss:\n",
    "        save_checkpoint(valid_loss)\n",
    "        best_valid_loss = valid_loss\n",
    "\n",
    "    # Prints the stats relative to the current epoch.\n",
    "    print(f\"EPOCHS : {i+1} train_loss : {train_loss} valid_loss : {valid_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTA E' LA FUNZIONE PER GENERARE I VETTORI DI ENCODING\n",
    "def get_encoding_csv(model, anc_img_path):\n",
    "  anc_img_names_arr = np.array(anc_img_path)\n",
    "  encodings = []\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for image in tqdm(anc_img_names_arr):\n",
    "      A = io.imread(DATASET_PATH + image)\n",
    "      #A = torch.from_numpy(A).permute(2, 0, 1) / 255.0\n",
    "      A = np.expand_dims(A, 0)\n",
    "      A = torch.from_numpy(A.astype(np.int32)) / 255.0\n",
    "      A = A.to(DEVICE)\n",
    "      A_enc = model(A.unsqueeze(0))\n",
    "      encodings.append(A_enc.squeeze().cpu().detach().numpy())\n",
    "\n",
    "    encodings = np.array(encodings)\n",
    "    encodings = pd.DataFrame(encodings)\n",
    "    df_enc = pd.concat([anc_img_path, encodings], axis = 1)\n",
    "\n",
    "    return df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ae47f969044cfa82f0636d4d2dab0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#QUI RICARICO IL MODELLO UNA VOLTA TRAINATO\n",
    "model.load_state_dict(torch.load(DATASET_PATH + 'best_model.pt'))\n",
    "\n",
    "#QUI CREO IL DATABASE DI FEATURE VECTORS DEL TRAINING SET\n",
    "df_enc = get_encoding_csv(model, df['anchor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc.to_csv('database.csv', index = False)\n",
    "\n",
    "df_enc = pd.read_csv(DATASET_PATH + 'embedded.csv')\n",
    "df_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(img_enc, anc_enc_arr):\n",
    "    #dist = np.s qrt(np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T))\n",
    "    dist = np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T)\n",
    "    #dist = np.sqrt(dist)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageEmbeddings(img, model):\n",
    "\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = torch.from_numpy(img) / 255\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        img = img.to(DEVICE)\n",
    "        img_enc = model(img.unsqueeze(0))\n",
    "        img_enc = img_enc.detach().cpu().numpy()\n",
    "        img_enc = np.array(img_enc)\n",
    "\n",
    "    return img_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchInDatabase(img_enc, database):\n",
    "    anc_enc_arr = database.iloc[:, 1:].to_numpy()\n",
    "    anc_img_names = database['Anchor']\n",
    "\n",
    "    distance = []\n",
    "    for i in range(anc_enc_arr.shape[0]):\n",
    "        dist = euclidean_dist(img_enc, anc_enc_arr[i : i+1, :])\n",
    "        distance = np.append(distance, dist)\n",
    "\n",
    "    closest_idx = np.argsort(distance)\n",
    "\n",
    "    return database['Anchor'][closest_idx[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
