{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import DatasetPath\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import timm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = DatasetPath.effectivePath\n",
    "INPUT_CSV_FILE = DATASET_PATH + \"input.csv\"\n",
    "\n",
    "with open(DATASET_PATH + 'best_valid_loss.txt', 'w') as file:\n",
    "    file.write(str(np.inf))\n",
    "\n",
    "#ATTENZIONE, IL BATCH SIZE VA REGOLATO IN BASE ALLA DISPONIBILITA' DELLA VOSTRA MEMORIA. TENETE CONTO CHE IO HO 128 CON 6GB DI MEMORIA GPU\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "#ATTENZIONE, IL LEARNING RATE ANCHE E' UN ALTRO IPER PARAMETRO IO HO FATTO LE PROVE SONO CON QUESTO.\n",
    "LR = 0.001\n",
    "\n",
    "#ATTENZIONE, L'EPOCHE DI TRAINING E' UN ALTRO IPERPARAMETRO IO PER ORA L'HO SETTATO COSI, MA SI PUò AUMENTARE O DIMINUIRE\n",
    "EPOCHS = 5\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_CSV_FILE)\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size = 0.20, random_state = 42)\n",
    "print(len(train_df))\n",
    "print(len(valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNZIONE PER CARICARE LE IMMAGINI DAL FILE CSV E SETTARLE NEL MODO CORRETO PER ESSERE DATE COME INPUT ALLA RETE NEURALE\n",
    "class APN_Dataset(Dataset):\n",
    "\n",
    "  def __init__(self, df):\n",
    "    self.df = df\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    row = self.df.iloc[idx]\n",
    "\n",
    "    A_img = io.imread(DATASET_PATH + row.anchor)\n",
    "    P_img = io.imread(DATASET_PATH + row.positive)\n",
    "    N_img = io.imread(DATASET_PATH + row.negative)\n",
    "\n",
    "    #Permute because the third channel has to be in first channel in torch\n",
    "\n",
    "    #A_img = torch.from_numpy(A_img).permute(2, 0, 1) / 255.0\n",
    "    #P_img = torch.from_numpy(P_img).permute(2, 0, 1) / 255.0\n",
    "    #N_img = torch.from_numpy(N_img).permute(2, 0, 1) / 255.0\n",
    "\n",
    "\n",
    "    A_img = np.expand_dims(A_img, 0)\n",
    "    P_img = np.expand_dims(P_img, 0)\n",
    "    N_img = np.expand_dims(N_img, 0)\n",
    "\n",
    "    A_img = torch.from_numpy(A_img) / 255.0\n",
    "    P_img = torch.from_numpy(P_img) / 255.0\n",
    "    N_img = torch.from_numpy(N_img) / 255.0\n",
    "\n",
    "    #A_img = torch.from_numpy(A_img.astype(np.int32)) / 65536.0\n",
    "    #P_img = torch.from_numpy(P_img.astype(np.int32)) / 65536.0\n",
    "    #N_img = torch.from_numpy(N_img.astype(np.int32)) / 65536.0\n",
    "\n",
    "    return A_img, P_img, N_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of trainset: 16000\n",
      "Size of validset: 4000\n"
     ]
    }
   ],
   "source": [
    "trainset = APN_Dataset(train_df)\n",
    "validset = APN_Dataset(valid_df)\n",
    "\n",
    "print(f\"Size of trainset: {len(trainset)}\")\n",
    "print(f\"Size of validset: {len(validset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of batches in trainloader : 250\n",
      "No. of batches in validloader : 63\n"
     ]
    }
   ],
   "source": [
    "trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "validloader = DataLoader(validset, batch_size = BATCH_SIZE)\n",
    "\n",
    "print(f\"No. of batches in trainloader : {len(trainloader)}\")\n",
    "print(f\"No. of batches in validloader : {len(validloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNZIONE PER CARICARE IL MODELLO DI RETE NEURALE DIRETTAMENTE DALLE REPOSITORY ONLINE\n",
    "class APN_Model(nn.Module):\n",
    "\n",
    "    #QUI DEFINISCO LA SIZE DEL VETTORE DI EMBEDDING\n",
    "  def __init__(self, emb_size = 512):\n",
    "    super(APN_Model, self).__init__()\n",
    "\n",
    "    #QUI CAIRCATE IL MODELLO, IN QUESTO CASO EFFICIENTNET VERSIONE B0 (LA PIù LEGGERA DELLA FAMIGLIA)\n",
    "    self.efficientnet = timm.create_model('tf_efficientnetv2_b0', pretrained = False)\n",
    "    self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features = emb_size)\n",
    "\n",
    "  def forward(self, images):\n",
    "    embeddings = self.efficientnet(images)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUI FATE UNA PICCOLA MODIFICA ALLA RETE PER FARLE AVERE IN INPUT IMMAGINI IN SCALA DI GRIGIO DELLO SPETTRO DI FOURIER\n",
    "model = APN_Model()\n",
    "model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNZIONE DI TRAINING\n",
    "def train_fn(model, dataloader, optimizer, criterion):\n",
    "  model.train() #ON Dropout\n",
    "  total_loss = 0.0\n",
    "  \n",
    "  for A, P, N in tqdm(dataloader, desc=\"Training Progress\"):\n",
    "    A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
    "    A_embs = model(A)\n",
    "    P_embs = model(P)\n",
    "    N_embs = model(N)\n",
    "    loss = criterion(A_embs, P_embs, N_embs)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "  return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNZIONE DI EVALUATION\n",
    "def eval_fn(model, dataloader, criterion):\n",
    "  model.eval() #OFF Dropout\n",
    "  total_loss = 0.0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for A, P, N in tqdm(dataloader, desc = \"Validation progress\"):\n",
    "      A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
    "\n",
    "      A_embs = model(A)\n",
    "      P_embs = model(P)\n",
    "      N_embs = model(N)\n",
    "\n",
    "      loss = criterion(A_embs, P_embs, N_embs)\n",
    "\n",
    "      total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUI UTILIZZATE LA TRIPLET LOSS E COME OTTIMIZZATORE ADAM. PER IL MOMENTO VI SCONSIGLIO DI CAMBIARE ADAM\n",
    "criterion = nn.TripletMarginLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = DATASET_PATH + 'best_model.pt'\n",
    "loss_path =  DATASET_PATH + 'best_valid_loss.txt'\n",
    "\n",
    "def save_checkpoint(best_valid_loss):\n",
    "  \"\"\"\n",
    "  Saves best model along with its valid loss to a '.txt' file\n",
    "\n",
    "  Parametres\n",
    "  ----------\n",
    "    best_valid_loss (float): the best valid loss calculated among all training sessions.\n",
    "  \"\"\"\n",
    "  torch.save(model.state_dict(), model_path)\n",
    "  with open(loss_path, 'w') as f:\n",
    "    f.write(str(best_valid_loss))\n",
    "  \n",
    "  print(\"CHECKPOINT_SAVED\")\n",
    "\n",
    "\n",
    "def load_checkpoint():\n",
    "  \"\"\"\n",
    "  Loads the best model and its valid loss from a '.txt' file. In case one of these can't be found, the training starts from scratch\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "    best_valid_loss (float, np.Inf): if the best valid loss exists, returns a float; else returns an Infinite value\n",
    "  \"\"\"\n",
    "  if os.path.exists(model_path) and os.path.exists(loss_path):\n",
    "    print(\"CHECKPOINT_LOADED\")\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    with open(loss_path, 'r') as f:\n",
    "      best_valid_loss = float(f.read())\n",
    "      return best_valid_loss\n",
    "  \n",
    "  print(\"UNABLE_TO_LOAD_CHECKPOINT\")\n",
    "  return np.Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUI FATE IL TRAINING VERO E PROPRIO UTILIZZANDO TUTTE LE FUNZIONI CHE AVETE VISTO IN PRECEDENZA\n",
    "best_valid_loss = load_checkpoint()\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "\n",
    "  train_loss = train_fn(model, trainloader, optimizer, criterion)\n",
    "  valid_loss = eval_fn(model, validloader, criterion)\n",
    "\n",
    "  if valid_loss < best_valid_loss:\n",
    "    save_checkpoint(valid_loss)\n",
    "    best_valid_loss = valid_loss\n",
    "\n",
    "  print(f\"EPOCHS : {i+1} train_loss : {train_loss} valid_loss : {valid_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTA E' LA FUNZIONE PER GENERARE I VETTORI DI ENCODING\n",
    "def get_encoding_csv(model, anc_img_path):\n",
    "  anc_img_names_arr = np.array(anc_img_path)\n",
    "  encodings = []\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for image in tqdm(anc_img_names_arr):\n",
    "      A = io.imread(DATASET_PATH + image)\n",
    "      #A = torch.from_numpy(A).permute(2, 0, 1) / 255.0\n",
    "      A = np.expand_dims(A, 0)\n",
    "      A = torch.from_numpy(A.astype(np.int32)) / 255.0\n",
    "      A = A.to(DEVICE)\n",
    "      A_enc = model(A.unsqueeze(0))\n",
    "      encodings.append(A_enc.squeeze().cpu().detach().numpy())\n",
    "\n",
    "    encodings = np.array(encodings)\n",
    "    encodings = pd.DataFrame(encodings)\n",
    "    df_enc = pd.concat([anc_img_path, encodings], axis = 1)\n",
    "\n",
    "    return df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ae47f969044cfa82f0636d4d2dab0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#QUI RICARICO IL MODELLO UNA VOLTA TRAINATO\n",
    "model.load_state_dict(torch.load(DATASET_PATH + 'best_model.pt'))\n",
    "\n",
    "#QUI CREO IL DATABASE DI FEATURE VECTORS DEL TRAINING SET\n",
    "df_enc = get_encoding_csv(model, df['anchor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc.to_csv('database.csv', index = False)\n",
    "\n",
    "df_enc = pd.read_csv(DATASET_PATH + 'embedded.csv')\n",
    "df_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(img_enc, anc_enc_arr):\n",
    "    #dist = np.s qrt(np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T))\n",
    "    dist = np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T)\n",
    "    #dist = np.sqrt(dist)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageEmbeddings(img, model):\n",
    "\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = torch.from_numpy(img) / 255\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        img = img.to(DEVICE)\n",
    "        img_enc = model(img.unsqueeze(0))\n",
    "        img_enc = img_enc.detach().cpu().numpy()\n",
    "        img_enc = np.array(img_enc)\n",
    "\n",
    "    return img_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchInDatabase(img_enc, database):\n",
    "    anc_enc_arr = database.iloc[:, 1:].to_numpy()\n",
    "    anc_img_names = database['Anchor']\n",
    "\n",
    "    distance = []\n",
    "    for i in range(anc_enc_arr.shape[0]):\n",
    "        dist = euclidean_dist(img_enc, anc_enc_arr[i : i+1, :])\n",
    "        distance = np.append(distance, dist)\n",
    "\n",
    "    closest_idx = np.argsort(distance)\n",
    "\n",
    "    return database['Anchor'][closest_idx[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
