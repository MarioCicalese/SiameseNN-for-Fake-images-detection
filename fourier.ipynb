{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import timm\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "\n",
    "from skimage.restoration import (\n",
    "    denoise_tv_chambolle,\n",
    "    denoise_bilateral,\n",
    "    denoise_wavelet,\n",
    "    estimate_sigma,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list_fourier = \"C:\\\\Users\\\\polsi\\\\Downloads\\\\TestSet\\\\TestSet\\\\biggan_256\\\\\"\n",
    "\n",
    "dir_list = np.array(os.listdir(dir_list_fourier))\n",
    "\n",
    "#Qui va il numero di mmagini che volete analizzare\n",
    "numImages = 1000\n",
    "\n",
    "dir_list = dir_list[0:numImages]\n",
    "\n",
    "#Qui va la dimensione delle immagini che volete analizzare\n",
    "superImage = np.zeros((256, 256, 3))\n",
    "\n",
    "#In questo for calcolo il residuo di ciascuna immagine e lo sommo di volta in volta\n",
    "for filename in tqdm(dir_list):\n",
    "    img = cv2.imread(dir_list_fourier + filename)\n",
    "\n",
    "    #Di seguito sono commentate diverse tecniche per il calcolo dei residui? Ne esistono delle migliori? Ditemelo voi! :)\n",
    "    currentResidual = img - gaussian_filter(img, sigma=1)\n",
    "    #currentResidual = img - median_filter(img, size=4)\n",
    "    #currentResidual = img - denoise_bilateral(img, sigma_color=0.1, sigma_spatial=4, channel_axis=-1)\n",
    "    #currentResidual = img - denoise_wavelet(img, channel_axis=-1, convert2ycbcr=True, rescale_sigma=True)\n",
    "    #currentResidual = img - denoise_tv_chambolle(img, weight=0.1, channel_axis=-1)\n",
    "\n",
    "    superImage = superImage + currentResidual\n",
    "\n",
    "#Qui alla fine faccio la media\n",
    "superImage = superImage / numImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qui visualizzo l'immagine della media dei residue e poi la trasformo con fourier\n",
    "\n",
    "superImage = np.float32(superImage/255)\n",
    "plt.imshow(superImage)\n",
    "plt.show()\n",
    "\n",
    "grayImg = cv2.cvtColor(superImage, cv2.COLOR_BGR2GRAY)\n",
    "print(grayImg.shape)\n",
    "\n",
    "img = np.float32(grayImg) / 255.0\n",
    "\n",
    "\n",
    "fft_img = np.fft.fft2(grayImg)\n",
    "\n",
    "fft_img = np.log(np.abs(fft_img))\n",
    "fft_min = np.percentile(fft_img, 5)\n",
    "fft_max = np.percentile(fft_img, 95)\n",
    "\n",
    "#Questa Ã¨ una normalizzazione che ho trovato su un codice. Serve a mettere in risalto le fingerprint\n",
    "if (fft_max - fft_min) <= 0:\n",
    "    print('ma cosa...')\n",
    "    fft_img = (fft_img - fft_min) / ((fft_max - fft_min)+np.finfo(float).eps)\n",
    "else:\n",
    "    fft_img = (fft_img - fft_min) / (fft_max - fft_min)\n",
    "    fft_img = (fft_img - 0.5) * 2\n",
    "    fft_img[fft_img < -1] = -1\n",
    "    fft_img[fft_img > 1] = 1\n",
    "\n",
    "plt.imshow(fft_img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
