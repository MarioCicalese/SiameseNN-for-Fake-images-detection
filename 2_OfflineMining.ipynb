{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from constants import DatasetPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Dataset folder path\n",
    "DATA_DIR = DatasetPath.effectivePath\n",
    "\n",
    "# Device to run calculations on \n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "REAL_DIRS = [\"afhq\", \"celebahq\", \"coco\", \"ffhq\", \"imagenet\", \"landscape\", \"lsun\", \"metfaces\", \"cycle_gan\", \"pro_gan\"]\n",
    "\n",
    "FAKE_DIRS = [\"big_gan\", \"cips\", \"cycle_gan\", \"ddpm\", \"denoising_diffusion_gan\", \"diffusion_gan\", \"face_synthetics\", \n",
    "\t\t\t\t \"gansformer\", \"gau_gan\", \"generative_inpainting\", \"glide\", \"lama\", \"latent_diffusion\", \"mat\", \"palette\", \n",
    "\t\t\t\t \"pro_gan\", \"projected_gan\", \"sfhq\", \"stable_diffusion\", \"star_gan\", \"stylegan1\", \"stylegan2\", \"stylegan3\",\n",
    "\t\t\t\t \"taming_transformer\", \"vq_diffusion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read '.csv' file containing 'anchor', 'positive' and 'negative' triplets\n",
    "df = pd.read_csv(DATA_DIR + \"pre_trainingSet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APN_Model(nn.Module):\n",
    "\t\"\"\"\n",
    "\tDefines a neural network model class APN_Model that uses an EfficientNet (specifically the B0 version) as its backbone.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, emb_size = 512):\n",
    "\t\t\"\"\"\n",
    "\t\tInitializes the APN_Model with a specific model and a classifier that outputs embedding vector of the specified size.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\temb_size (int, optional): the size of the output embedding vector (default is 512).\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(APN_Model, self).__init__()\n",
    "\n",
    "\t\t# Define the model to use \n",
    "\t\tself.efficientnet = timm.create_model('tf_efficientnetv2_b0', pretrained = True)\n",
    "\t\t\n",
    "\t\t# Replace the classifier layer with a linear layer that outputs embeddings of size `emb_size`\n",
    "\t\tself.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features = emb_size)\n",
    "\n",
    "\tdef forward(self, images):\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms the forward pass of the model, which takes a batch of images and returns their embeddings.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\t\timages (torch.Tensor): a batch of images to process.\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\t\tembeddings (torch.Tensor): a batch of embeddings of size `emb_size`.\n",
    "\t\t\"\"\"\n",
    "\t\tembeddings = self.efficientnet(images)\n",
    "\t\treturn embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN mod to accept greyscale fourier spectrum images instead of RGB\n",
    "\n",
    "model = APN_Model()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMBEDDINGS CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageEmbeddings(img_path, model):\n",
    "\t\"\"\"\n",
    "\tGenerates embeddings for a given image using the provided model.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\t\timg_path (str): the path to the input image.\n",
    "\t\tmodel (torch.nn.Module): the PyTorch model used to generate the image embeddings.\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\t\timg_enc (numpy.ndarray): the embeddings of the input image.\n",
    "\t\"\"\"\n",
    "\tpreprocess = transforms.Compose([\n",
    "\t\ttransforms.ToTensor(),  # Convert the image to a PyTorch tensor and normalize pixel values to [0, 1]\n",
    "\t\ttransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "\t])\n",
    "\t\n",
    "\t# Read the image from the specified directory\n",
    "\timg = Image.open(DATA_DIR + img_path).convert('RGB')\n",
    "\t# Image preprocessing\n",
    "\timg = preprocess(img).unsqueeze(0)  # Add a batch dimension\n",
    "\t# Move the image tensor to the appropriate device (CPU or GPU)\n",
    "\timg = img.to(DEVICE)\n",
    "\t\n",
    "\t# Set the model to evaluation mode\n",
    "\tmodel.eval()\n",
    "\t\n",
    "\t# Disable gradient calculation for efficiency\n",
    "\twith torch.no_grad():\n",
    "\t\t\n",
    "\t\t# Pass the image through the model to get the embeddings\n",
    "\t\timg_enc = model(img)\n",
    "\t\t\n",
    "\t\t# Detach the embeddings from the computation graph and move them back to the CPU\n",
    "\t\timg_enc = img_enc.detach().cpu().numpy()\n",
    "\n",
    "\treturn img_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = {}  # Initialize an empty dictionary to store image embeddings\n",
    "\n",
    "pre_training_df = pd.read_csv(DATA_DIR + \"pre_trainingSet.csv\")\n",
    "\n",
    "# Loop through each image path in the 'anchor' column of the DataFrame\n",
    "for img_path in tqdm(pre_training_df['image_path'], total=len(pre_training_df), desc=\"Generating embeddings\"):\n",
    "\t# Generate and store the embedding for each anchor image in the dictionary\n",
    "\tembedding_dict[img_path] = getImageEmbeddings(img_path, model)\n",
    "\n",
    "# Map the embeddings to the 'anchor_emb' column using the paths from the 'anchor' column\n",
    "df['anchor_emb'] = df['anchor'].map(embedding_dict)\n",
    "\n",
    "# Map the embeddings to the 'positive_emb' column using the paths from the 'positive' column\n",
    "df['positive_emb'] = df['positive'].map(embedding_dict)\n",
    "\n",
    "# Map the embeddings to the 'negative_emb' column using the paths from the 'negative' column\n",
    "df['negative_emb'] = df['negative'].map(embedding_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISTANCES CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a (numpy.ndarray): the first vector.\n",
    "    b (numpy.ndarray): the second vector.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (float): the Euclidean distance between vectors `a` and `b`.\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(a - b)  # Calculate and return the Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distances between anchor and positive embeddings\n",
    "df['dist_anchor_positive'] = [euclidean_distance(row['anchor_emb'], row['positive_emb']) for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Calculating distances (anchor-positive)\")]\n",
    "\n",
    "# Calculate the distances between anchor and negative embeddings\n",
    "df['dist_anchor_negative'] = [euclidean_distance(row['anchor_emb'], row['negative_emb']) for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Calculating distances (anchor-negative)\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEMI-HARD TRIPLETS FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2  # Set the margin for semi-hard triplets\n",
    "\n",
    "# Filter the DataFrame to select semi-hard triplets based on the defined condition\n",
    "semi_hard_triplets = df[\n",
    "    (df['dist_anchor_positive'] < df['dist_anchor_negative']) &  # Check if the distance between anchor and positive embeddings is less than the distance between anchor and negative embeddings\n",
    "    (df['dist_anchor_negative'] < (df['dist_anchor_positive'] + margin))  # Check if the distance between anchor and negative embeddings is less than the distance between anchor and positive embeddings plus the margin\n",
    "]\n",
    "\n",
    "# Print the semi-hard triplets\n",
    "print(semi_hard_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK FOR SUCCESSFULL OPERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame containing only the 'anchor', 'positive', and 'negative' columns from semi_hard_triplets\n",
    "filtered_df = semi_hard_triplets[['anchor', 'positive', 'negative']].copy()\n",
    "\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STORING PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(df, filename, path):\n",
    "\t\"\"\"\n",
    "\tSplits the DataFrame in chunks to enable tqdm progress visualization while converting the DataFrame into a '.csv' file.\n",
    "\n",
    "\tParametres\n",
    "\t----------\n",
    "\t\tdf (pd.DataFrame): the DataFrame to convert.\n",
    "\t\tfilename (str): the desired file name (comprehensive of '.csv' extension).\n",
    "\t\tpath (str): the path where the '.csv' will be stored.\n",
    "\t\"\"\"\n",
    "\tchunks = np.array_split(df.index, 100)\n",
    "\tfor chunck, subset in enumerate(tqdm(chunks, desc=\"Creating \\'\" + filename + \"\\' file\")):\n",
    "\t\tif chunck == 0: # first row\n",
    "\t\t\tdf.loc[subset].to_csv(path, mode='w', index=False)\n",
    "\t\telse:\n",
    "\t\t\tdf.loc[subset].to_csv(path, header=None, mode='a', index=False)\n",
    "\n",
    "\tprint(\"\\'\" + filename + \"\\' has been successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to '.csv'\n",
    "df_to_csv(filtered_df, \"RGB_trainingSet.csv\", DATA_DIR + \"RGB_trainingSet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOT GENERATION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mining_aftermaths(df, filtered_df):\n",
    "    \"\"\"\n",
    "    Plots a horizontal bar chart comparing the number of potential triplets to the actual triplets \n",
    "    after filtering operations.\n",
    "\n",
    "    This function is used to visualize the effectiveness of the filtering process by showing the \n",
    "    reduction in the number of triplets from the potential set (before filtering) to the actual set \n",
    "    (after filtering).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df (pandas.DataFrame): The DataFrame containing the initial set of potential triplets.\n",
    "    filtered_df (pandas.DataFrame): The DataFrame containing the filtered set of actual triplets.\n",
    "    \"\"\"\n",
    "    # Calculate the number of potential and actual triplets from the dataframes\n",
    "    potential_triplets = len(df)\n",
    "    actual_triplets = len(filtered_df)\n",
    "\n",
    "    # Prepare data for plotting: create a DataFrame for easy plotting\n",
    "    lengths = {'Actual': actual_triplets, 'Potential': potential_triplets}\n",
    "    lengths_df = pd.DataFrame(list(lengths.items()), columns=['File', 'Length'])\n",
    "\n",
    "    # Plot a horizontal bar chart to show the comparison\n",
    "    ax = lengths_df.plot(kind='barh', x='File', y='Length', legend=False, color=['blue', 'red'])\n",
    "    plt.title('Number of Generated Semi-Hard Triplets')\n",
    "    plt.xlabel('Number of Triplets')\n",
    "    plt.ylabel('File')\n",
    "\n",
    "    # Add text annotations directly to the bars to show exact numbers\n",
    "    for index, value in enumerate(lengths_df['Length']):\n",
    "        ax.text(value, index, str(value), va='center')\n",
    "\n",
    "    # Adjust the x-axis limit to accommodate the annotations for clarity\n",
    "    plt.xlim(right=max(lengths_df['Length']) * 1.1)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "def plot_path_frequency_as_positive(df):\n",
    "\t\"\"\"\n",
    "\tPlot the frequency of paths in the 'positive' column of the DataFrame.\n",
    "\n",
    "\tThis function calculates the frequency of each unique path in the 'positive'\n",
    "\tcolumn of the provided DataFrame and plots the top 20 most frequent paths\n",
    "\tas a bar chart.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tdf (pandas.DataFrame): the DataFrame containing the 'positive' column with paths.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t# Calculate the frequency of 'positive' paths\n",
    "\tpositive_counts = df['positive'].value_counts()\n",
    "\n",
    "\t# Create the bar plot\n",
    "\tplt.figure(figsize=(25, 5))\n",
    "\tpositive_counts.head(20).plot(kind='bar')\n",
    "\tplt.title('Most Frequent Paths as \\'Positive\\'')\n",
    "\tplt.xlabel('Path')\n",
    "\tplt.ylabel('Frequency')\n",
    "\tplt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "\tplt.show()\n",
    "\n",
    "def plot_path_frequency_as_negative(df):\n",
    "\t\"\"\"\n",
    "\tPlot the frequency of paths in the 'negative' column of the DataFrame.\n",
    "\n",
    "\tThis function calculates the frequency of each unique path in the 'negative'\n",
    "\tcolumn of the provided DataFrame and plots the top 20 most frequent paths\n",
    "\tas a bar chart.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tdf (pandas.DataFrame): the DataFrame containing the 'negative' column with paths.\n",
    "\t\"\"\"\n",
    "\t# Calculate the frequency of 'negative' paths\n",
    "\tnegative_counts = df['negative'].value_counts()\n",
    "\n",
    "\t# Create the bar plot\n",
    "\tplt.figure(figsize=(25, 5))\n",
    "\tnegative_counts.head(20).plot(kind='bar')\n",
    "\tplt.title('Most Frequent Paths as \\'Negative\\'')\n",
    "\tplt.xlabel('Path')\n",
    "\tplt.ylabel('Frequency')\n",
    "\tplt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "\tplt.show()\n",
    "\n",
    "def plot_real_fake_count(df, dataset_partition_path):\n",
    "\t\"\"\"\n",
    "\tPlot the count of 'real' and 'fake' images based on the target information from a separate CSV file.\n",
    "\n",
    "\tThis function merges the DataFrame containing image paths with another DataFrame that categorizes\n",
    "\teach image as 'real' or 'fake' based on the 'target' column. It then plots these counts as a horizontal bar chart.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tdf (pandas.DataFrame): DataFrame containing 'anchor', 'positive', and 'negative' columns with image paths.\n",
    "\tdataset_partition_path (str): Path to the CSV file containing 'image_path' and 'target' columns.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t# Load the dataset partition DataFrame\n",
    "\tdataset_partition_df = pd.read_csv(dataset_partition_path)\n",
    "\t\n",
    "\t# Merge the anchor paths with the partition DataFrame to get their targets\n",
    "\tdf = df.merge(dataset_partition_df, left_on='anchor', right_on='image_path', how='left')\n",
    "\n",
    "\t# Determine the 'Type' based on the 'target' column\n",
    "\tdf['Type'] = df['target'].apply(lambda x: 'real' if x == 0 else 'fake')\n",
    "\n",
    "\t# Count occurrences of 'real' and 'fake'\n",
    "\tcounts = df['Type'].value_counts()\n",
    "\n",
    "\t# Prepare data for plotting\n",
    "\tcounts_df = pd.DataFrame(counts).reset_index()\n",
    "\tcounts_df.columns = ['Type', 'Count']\n",
    "\n",
    "\t# Plot horizontal bar chart\n",
    "\tax = counts_df.plot(kind='barh', x='Type', y='Count', legend=False, color=['blue', 'red'])\n",
    "\tplt.title('Number of images per category in the Training Set')\n",
    "\tplt.xlabel('Count')\n",
    "\tplt.ylabel('Type')\n",
    "\n",
    "\t# Add text annotations to the bars\n",
    "\tfor index, value in enumerate(counts_df['Count']):\n",
    "\t\tax.text(value, index, str(value), va='center')\n",
    "\n",
    "\t# Expand x-axis to accommodate annotations\n",
    "\tplt.xlim(right=max(counts_df['Count']) * 1.2)\n",
    "\n",
    "\tplt.show()\n",
    "\n",
    "def plot_apn_count_by_source(train_df, apn='anchor'):\n",
    "\t\"\"\"\n",
    "\tPlots a bar chart showing the number of 'anchor' images for each source.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\ttrain_df (pandas.DataFrame): The dataframe containing the semi-hard mined triplets.\n",
    "\tapn (str, optional): 'anchor', 'positive' or 'negative', specifies on which member the count should be executed. Default: 'anchor'. \n",
    "\t\"\"\"\n",
    "\t# Count the number of images in each directory\n",
    "\tdir_count = {}\n",
    "\tfor index, row in tqdm(train_df.iterrows(), total=train_df.shape[0], desc=\"Counting images\"):\n",
    "\t\tdir = row[apn].split('/')[0]\n",
    "\t\tif dir in dir_count:\n",
    "\t\t\tdir_count[dir] += 1\n",
    "\t\telse:\n",
    "\t\t\tdir_count[dir] = 1\n",
    "\n",
    "\t# Sort the directories by name\n",
    "\tsorted_dirs = sorted(dir_count.items())\n",
    "\n",
    "\t# Extract the directory names and counts\n",
    "\tdirs, counts = zip(*sorted_dirs)\n",
    "\n",
    "\t# Create the bar chart with different colors\n",
    "\tcolors = plt.cm.viridis(np.linspace(0, 1, len(dirs)))  # Use the viridis colormap\n",
    "\n",
    "\t# Create the bar chart\n",
    "\tplt.figure(figsize=(10, 6))\n",
    "\tplt.bar(dirs, counts, color=colors)\n",
    "\tplt.xlabel('Sources')\n",
    "\tplt.ylabel('Number of Images')\n",
    "\tplt.title(f'Number of \\'{apn}\\' Images per Source')\n",
    "\tplt.xticks(rotation=90)\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mining_aftermaths(df, filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path_frequency_as_positive(filtered_df)\n",
    "plot_path_frequency_as_negative(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_real_fake_count(filtered_df, DATA_DIR + \"pre_trainingSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_apn_count_by_source(filtered_df)\n",
    "plot_apn_count_by_source(filtered_df, 'positive')\n",
    "plot_apn_count_by_source(filtered_df,'negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST SET REBALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dirs(filtered_input_df):\n",
    "\t\"\"\"\n",
    "\tRetrieves image source directories from the dataset.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\t\tfiltered_input_df (pandas.DataFrame): the dataframe containing the semi-hard mined triplets.\n",
    "\tReturns\n",
    "\t-------\n",
    "\t\treal_dirs (set of str): a set of unique directories that contain real images.\n",
    "\t\tfake_dirs (set of str): a set of unique directories that contain fake images.\n",
    "\t\"\"\"\n",
    "\t# Initialize lists to store directories for real and fake images\n",
    "\treal_dirs_list = []\n",
    "\tfake_dirs_list = []\n",
    "\n",
    "\t# Iterate through each row in the dataframe with a progress bar\n",
    "\tfor index, row in tqdm(filtered_input_df.iterrows(), total=filtered_input_df.shape[0]):\n",
    "\t\t# Extract the top-level directory from the image path\n",
    "\t\tdir = row[\"anchor\"].split('/')[0]\n",
    "\n",
    "\t\t# Categorize the directory as 'real' or 'fake' based on its presence in REAL_DIRS\n",
    "\t\tif dir in REAL_DIRS:\n",
    "\t\t\treal_dirs_list.append(dir)\n",
    "\t\telse:\n",
    "\t\t\tfake_dirs_list.append(dir)\n",
    "\n",
    "\treal_dirs = sorted(set(real_dirs_list))\n",
    "\tfake_dirs = sorted(set(fake_dirs_list))\n",
    "\n",
    "\t# Return the lists of real and fake directories\n",
    "\treturn real_dirs, fake_dirs\n",
    "\n",
    "\n",
    "def train_test_split_rebalance(train_df, test_df):\n",
    "\t\"\"\"\n",
    "\tRebalances the test dataset to achieve an 80/20 train-test split ratio.\n",
    "\n",
    "\tThis function rebalances the test dataset by dropping a calculated number of \n",
    "\tsamples from each directory of real and fake images to achieve an 80/20 \n",
    "\ttrain-test split ratio. The function also saves the old test set before \n",
    "\trebalancing.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tfiltered_input_df (pandas.DataFrame): the DataFrame containing the filtered input data.\n",
    "\ttest_df (pandas.DataFrame): the DataFrame containing the initial test data.\n",
    "\n",
    "\tNotes\n",
    "\t-----\n",
    "\t- This function assumes the presence of 'real' and 'fake' columns in the \n",
    "\t  `test_df` DataFrame, which contain paths to the real and fake images, \n",
    "\t  respectively.\n",
    "\t- The function will save the old test set to a CSV file named \n",
    "\t  \"unbalanced_testSet.csv\" and the rebalanced test set to a CSV file named \n",
    "\t  \"testSet.csv\" in the directory specified by `DATA_DIR`.\n",
    "\t- The function uses the helper function `get_input_dirs` to obtain directories \n",
    "\t  containing real and fake images and `df_to_csv` to save DataFrames to CSV files.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t# Initialization\n",
    "\tbalanced_test_df = pd.DataFrame(columns=['real', 'fake'])\n",
    "\tinput_size = len(train_df)\n",
    "\treal_dirs, fake_dirs = get_input_dirs(train_df)\n",
    "\tprint(real_dirs)\n",
    "\tprint(fake_dirs)\n",
    "\n",
    "\trebalanced_size = round(input_size * 20 / 80)\n",
    "\tprint(f\"Current Test set size:{len(test_df) * 2}(Train-Test split ratio: {(input_size * 100 / (input_size + (len(test_df)* 2))):.2f}/{(len(test_df) * 2 * 100 / (input_size + (len(test_df)* 2))):.2f})\")\n",
    "\tprint(f\"Balanced Test set size:{rebalanced_size}(Train-Test split ratio: 80/20)\")\n",
    "\n",
    "\t# Number of tuples to sample from each real images directory\n",
    "\treal_sample_size = round(rebalanced_size / 2 / len(real_dirs))\n",
    "\ti = 1\n",
    "\t#Iterate through the dataset partition and sample the same number of tuples for each fake images directory\n",
    "\tfor dir in tqdm(real_dirs, desc=\"Test set Real images sampling\"):\n",
    "\t\tsampled_size = 0\n",
    "\t\tfor index, row in test_df.iterrows():\n",
    "\t\t\tif sampled_size < real_sample_size:\n",
    "\t\t\t\timage_path = row[\"real\"]\n",
    "\t\t\t\tsplitted_path = image_path.split('/')[0]\n",
    "\t\t\t\tif dir==splitted_path:\n",
    "\t\t\t\t\tbalanced_test_df.loc[i] = [image_path, None]\n",
    "\t\t\t\t\tsampled_size+=1\n",
    "\t\t\t\t\ti+=1\n",
    "\t\t\telse: break\n",
    "\t\n",
    "\t# Number of tuples to sample from each fake images directory\n",
    "\tfake_sample_size = round(rebalanced_size / 2 / len(fake_dirs))\n",
    "\ti = 1\n",
    "\t#Iterate through the dataset partition and sample the same number of tuples for each fake images directory\n",
    "\tfor dir in tqdm(fake_dirs, desc=\"Test set Fake images sampling\"):\n",
    "\t\t\tsampled_size = 0\n",
    "\t\t\tfor index, row in test_df.iterrows():\n",
    "\t\t\t\t\tif sampled_size < fake_sample_size:\n",
    "\t\t\t\t\t\t\timage_path = row[\"fake\"]\n",
    "\t\t\t\t\t\t\tsplitted_path = image_path.split('/')[0]\n",
    "\t\t\t\t\t\t\tif dir == splitted_path:\n",
    "\t\t\t\t\t\t\t\t\tbalanced_test_df.loc[i] = [balanced_test_df.loc[i][\"real\"], image_path]\n",
    "\t\t\t\t\t\t\t\t\tsampled_size+=1\n",
    "\t\t\t\t\t\t\t\t\ti+=1\n",
    "\n",
    "\t\t\t\t\telse: break\n",
    "\t\n",
    "\tprint(f\"Test Set size after operations:{len(balanced_test_df) * 2}\")\n",
    "\n",
    "\t# Store the old version of the Test Set and Overwrite the Test Set with the rebalanced one\n",
    "\tdf_to_csv(test_df, \"unbalanced_RGB_testSet.csv\", DATA_DIR + \"unbalanced_RGB_testSet.csv\")\n",
    "\tif os.path.exists(DATA_DIR + \"RGB_testSet.csv\"):\n",
    "\t\tos.remove(DATA_DIR + \"RGB_testSet.csv\")\n",
    "\tdf_to_csv(balanced_test_df, \"RGB_testSet.csv\", DATA_DIR + \"RGB_testSet.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(DATA_DIR + \"RGB_testSet.csv\")\n",
    "\n",
    "train_test_split_rebalance(filtered_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK IF REBALANCING WAS SUCCESSFULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DETECTIVE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
